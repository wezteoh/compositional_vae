{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find gpu\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        lambda x: x>0.5,\n",
    "        lambda x: x.float(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "bsize = 100\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dset.MNIST('data', train=True, download=True, transform=data_transforms), batch_size=bsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dset.MNIST('data', train=False, download=True, transform=data_transforms), batch_size=bsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_LEVELS = 4\n",
    "tau = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_levels = NUM_LEVELS):\n",
    "        super(Encoder, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        \n",
    "        \n",
    "        self.tunnels = nn.ModuleList([nn.Linear(64,64) for _ in range(num_levels-1)])\n",
    "        self.codings = nn.ModuleList([nn.Linear(64,1) for _ in range(num_levels)])     \n",
    "#         self.codings = nn.ModuleList([nn.Linear(64,2**(num_levels-1-_)) for _ in range(num_levels)])     \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "#     def num_flat_features(self, x):\n",
    "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "#         num_features = 1\n",
    "#         for s in size:\n",
    "#             num_features *= s\n",
    "#         return num_features\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x= x.view(-1,1,28,28)\n",
    "#         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "#         # If the size is a square you can only specify a single number\n",
    "#         x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "#         sofar = self.relu(self.fc1(x))\n",
    "        \n",
    "        h = self.relu(self.fc1(x))\n",
    "        h = self.relu(self.fc2(h))\n",
    "        h = self.relu(self.fc3(h))\n",
    "        sofar = self.relu(self.fc4(h))\n",
    "        posteriors = [self.codings[0](sofar)]\n",
    "        for _ in range(len(self.tunnels)):\n",
    "            sofar = self.relu(self.tunnels[_](sofar))\n",
    "            posteriors.append(self.codings[_+1](sofar))\n",
    "#         posteriors.reverse()\n",
    "        return posteriors\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_levels=NUM_LEVELS):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_levels, 64)\n",
    "        self.fc2 = nn.Linear(64,128)\n",
    "        self.fc3 = nn.Linear(128,256)\n",
    "        self.fc4 = nn.Linear(256,784)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, code):\n",
    "        h = self.relu(self.fc1(code))\n",
    "        h = self.relu(self.fc2(h))\n",
    "        h = self.relu(self.fc3(h))\n",
    "        y = self.sigmoid(self.fc4(h))\n",
    "        return y\n",
    "\n",
    "# generative model network\n",
    "# used for generating cond latent distributions in training\n",
    "class Hierarchy(nn.Module):\n",
    "    def __init__(self, num_levels=NUM_LEVELS):\n",
    "        super(Hierarchy, self).__init__()\n",
    "        self.root_dist = nn.Parameter(torch.Tensor([0.0]))\n",
    "        self.downwards = nn.ModuleList([nn.Linear(1,1) for _ in range(num_levels-1)])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, codes):\n",
    "        # cast to batch size dimension\n",
    "#         root_dist = torch.Tensor([0.5])\n",
    "#         if cuda:\n",
    "#             root_dist = root_dist.cuda()\n",
    "#         root_dist = Variable(root_dist, requires_grad=False).repeat(codes[0].size()[0],1)\n",
    "#         cond_priors = [root_dist]\n",
    "        cond_priors = [F.sigmoid(self.root_dist).repeat(codes[0].size()[0],1)]\n",
    "        for _ in range(len(codes)-1):\n",
    "            cond_priors.append(self.sigmoid(self.downwards[_](codes[_])))\n",
    "        \n",
    "        return cond_priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_binary_concrete(inputs, temperature = tau):\n",
    "    U = Variable(torch.rand(inputs.shape), requires_grad=False)\n",
    "    return F.sigmoid((U.log() - (1-U).log() + inputs)/temperature)\n",
    "        \n",
    "def hard_sample_binary_concrete(inputs):\n",
    "    y = sample_binary_concrete(inputs)\n",
    "    y_hard = torch.round(y)\n",
    "    return (y_hard - y).detach() + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Encoder()\n",
    "D = Decoder()\n",
    "H = Hierarchy()\n",
    "if cuda:\n",
    "    E.cuda()\n",
    "    D.cuda()\n",
    "    H.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([\n",
    "                {'params':E.parameters()},\n",
    "                {'params': D.parameters()},\n",
    "                {'params': H.parameters()}\n",
    "            ], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    kld_loss = 0\n",
    "    rec_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = Variable(data, requires_grad=False)\n",
    "        x = data.view(-1,784)\n",
    "        posteriors = E(x)\n",
    "        codes = [hard_sample_binary_concrete(posterior) for posterior in posteriors]\n",
    "        cond_priors = H(codes)\n",
    "        codes = torch.cat(codes, dim=-1)\n",
    "        y = D(codes)\n",
    "        kld = KLD(cond_priors, posteriors)\n",
    "        rec = recon_loss(y, x)\n",
    "        loss = kld + rec\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data[0]\n",
    "        kld_loss += kld.data[0]\n",
    "        rec_loss += rec.data[0]\n",
    "#         plt.imshow(y[0].view(28,28).data.cpu().numpy())\n",
    "#         plt.show()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tKLD: {:.6f}\\trecon_loss:{:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                batch_idx*100/ len(train_loader),\n",
    "                loss.data[0], kld.data[0], rec.data[0]))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}\\tKLD: {:.6f}\\trecon_loss:{:.6f}'.format(\n",
    "          epoch+1, train_loss / len(train_loader), kld_loss/ len(train_loader), rec_loss/ len(train_loader)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLD(cond_priors, posteriors):\n",
    "    cond_priors = torch.cat(cond_priors, dim = -1)\n",
    "    posteriors = torch.cat(posteriors, dim = -1) \n",
    "    posteriors = F.sigmoid(posteriors)\n",
    "    const = 1E-20\n",
    "    kld_per_latent = posteriors * ((posteriors+const).log() - (cond_priors+const).log()) + \\\n",
    "                    (1-posteriors) * ((1-posteriors+const).log() - (1-cond_priors+const).log())\n",
    "#     kld_per_latent = posteriors * ((posteriors+const).log() - np.log(0.5)) + \\\n",
    "#                      (1-posteriors) * ((1-posteriors+const).log() - np.log(0.5))\n",
    "                                      \n",
    "    return kld_per_latent.sum(dim=-1).mean()\n",
    "    \n",
    "\n",
    "def recon_loss(y, true_y):\n",
    "    return F.binary_cross_entropy(y, true_y, size_average=False)/y.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.061829\tKLD: 0.092494\trecon_loss:542.969360\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 211.364059\tKLD: 0.689759\trecon_loss:210.674301\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 195.348877\tKLD: 1.393849\trecon_loss:193.955032\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 190.529785\tKLD: 1.214446\trecon_loss:189.315338\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 189.811127\tKLD: 1.377187\trecon_loss:188.433945\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 180.977905\tKLD: 1.348164\trecon_loss:179.629745\n",
      "====> Epoch: 1 Average loss: 201.5539\tKLD: 1.184000\trecon_loss:200.369941\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 192.139679\tKLD: 1.242995\trecon_loss:190.896683\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 181.352493\tKLD: 1.203874\trecon_loss:180.148621\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 175.462860\tKLD: 1.749571\trecon_loss:173.713287\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 178.284851\tKLD: 1.664954\trecon_loss:176.619904\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 179.858292\tKLD: 1.706936\trecon_loss:178.151352\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 186.267288\tKLD: 1.522090\trecon_loss:184.745193\n",
      "====> Epoch: 2 Average loss: 186.5697\tKLD: 1.511322\trecon_loss:185.058329\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 178.400284\tKLD: 1.545640\trecon_loss:176.854645\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 191.665237\tKLD: 1.419621\trecon_loss:190.245621\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 186.731262\tKLD: 1.420840\trecon_loss:185.310425\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 188.490555\tKLD: 1.355584\trecon_loss:187.134964\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 194.967194\tKLD: 1.273389\trecon_loss:193.693802\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 181.411865\tKLD: 1.594126\trecon_loss:179.817734\n",
      "====> Epoch: 3 Average loss: 183.9606\tKLD: 1.467114\trecon_loss:182.493454\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 184.068970\tKLD: 1.433095\trecon_loss:182.635880\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 175.907120\tKLD: 1.382483\trecon_loss:174.524643\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 178.815186\tKLD: 1.581393\trecon_loss:177.233795\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 172.617737\tKLD: 1.594710\trecon_loss:171.023026\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 183.202438\tKLD: 1.385042\trecon_loss:181.817398\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 185.061707\tKLD: 1.227306\trecon_loss:183.834396\n",
      "====> Epoch: 4 Average loss: 184.5582\tKLD: 1.343166\trecon_loss:183.215012\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 180.587540\tKLD: 1.312761\trecon_loss:179.274780\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 186.704636\tKLD: 1.149394\trecon_loss:185.555237\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 182.652481\tKLD: 1.315378\trecon_loss:181.337097\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 189.642929\tKLD: 1.080525\trecon_loss:188.562408\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 195.212616\tKLD: 0.736388\trecon_loss:194.476227\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 185.242493\tKLD: 1.049135\trecon_loss:184.193359\n",
      "====> Epoch: 5 Average loss: 188.2353\tKLD: 1.054797\trecon_loss:187.180517\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 184.490555\tKLD: 1.158935\trecon_loss:183.331619\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 195.854218\tKLD: 0.679328\trecon_loss:195.174896\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 190.257355\tKLD: 0.854338\trecon_loss:189.403015\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 193.758591\tKLD: 0.733940\trecon_loss:193.024643\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 189.478287\tKLD: 0.729837\trecon_loss:188.748444\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 193.411835\tKLD: 0.797385\trecon_loss:192.614456\n",
      "====> Epoch: 6 Average loss: 193.5086\tKLD: 0.780911\trecon_loss:192.727655\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 193.433212\tKLD: 0.602925\trecon_loss:192.830292\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 197.284470\tKLD: 0.434710\trecon_loss:196.849762\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 199.056885\tKLD: 0.330936\trecon_loss:198.725952\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 190.430145\tKLD: 0.513376\trecon_loss:189.916763\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 203.607513\tKLD: 0.502311\trecon_loss:203.105209\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 206.547226\tKLD: 0.258005\trecon_loss:206.289215\n",
      "====> Epoch: 7 Average loss: 199.5491\tKLD: 0.443479\trecon_loss:199.105575\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 199.766144\tKLD: 0.212294\trecon_loss:199.553848\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 203.945389\tKLD: 0.196731\trecon_loss:203.748657\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 205.111496\tKLD: 0.138258\trecon_loss:204.973236\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 211.675140\tKLD: 0.103940\trecon_loss:211.571198\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 199.313812\tKLD: 0.114437\trecon_loss:199.199371\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 208.898392\tKLD: 0.101573\trecon_loss:208.796814\n",
      "====> Epoch: 8 Average loss: 204.2878\tKLD: 0.165277\trecon_loss:204.122568\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 208.619110\tKLD: 0.144456\trecon_loss:208.474655\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 205.203400\tKLD: 0.095409\trecon_loss:205.107986\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 213.007248\tKLD: 0.084725\trecon_loss:212.922516\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 216.476898\tKLD: 0.042059\trecon_loss:216.434845\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 201.488998\tKLD: 0.038405\trecon_loss:201.450592\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 204.291382\tKLD: 0.074156\trecon_loss:204.217224\n",
      "====> Epoch: 9 Average loss: 205.4377\tKLD: 0.072642\trecon_loss:205.365050\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 209.587311\tKLD: 0.066619\trecon_loss:209.520691\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 204.356720\tKLD: 0.111408\trecon_loss:204.245316\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 199.116470\tKLD: 0.035063\trecon_loss:199.081406\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 202.397247\tKLD: 0.029749\trecon_loss:202.367493\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 202.484863\tKLD: 0.036129\trecon_loss:202.448730\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 200.689011\tKLD: 0.075359\trecon_loss:200.613647\n",
      "====> Epoch: 10 Average loss: 204.9307\tKLD: 0.083737\trecon_loss:204.846931\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "torch.manual_seed(142)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3c9e875c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 10, sharey=True, figsize=(10,1))\n",
    "plt.subplots_adjust(left=None, bottom=None, right=1.9, top=None,\n",
    "                wspace=None, hspace=None)\n",
    "for i in range(10):\n",
    "    l = [hard_sample_binary_concrete(H.root_dist.unsqueeze(0))]\n",
    "    for d in H.downwards:\n",
    "        l.append(hard_sample_binary_concrete(d(l[-1])))\n",
    "    l = torch.cat(l, dim=-1)\n",
    "    recovery = D(l).view(28,28).data.cpu().numpy()\n",
    "    ax = axes[i]\n",
    "    ax.set_title(l.cpu().data.numpy())\n",
    "    ax.imshow(recovery)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3c9e87b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 10, sharey=True, figsize=(10,1))\n",
    "plt.subplots_adjust(left=None, bottom=None, right=1.9, top=None,\n",
    "                wspace=None, hspace=None)\n",
    "for i in range(10):\n",
    "    l = [hard_sample_binary_concrete(H.root_dist.unsqueeze(0))]\n",
    "    for d in H.downwards:\n",
    "        l.append(hard_sample_binary_concrete(d(l[-1])))\n",
    "    l = torch.cat(l, dim=-1)\n",
    "    recovery = D(l).view(28,28).data.cpu().numpy()\n",
    "    ax = axes[i]\n",
    "    ax.set_title(l.cpu().data.numpy())\n",
    "    ax.imshow(recovery)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-725061ff35b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mblah\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblah\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mblah\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblah\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblah\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "blah = {}\n",
    "for k in range(500):\n",
    "    fixed = hard_sample_binary_concrete(H.root_dist.unsqueeze(0))\n",
    "    idx = int(fixed.cpu().data.numpy()[0][0])\n",
    "    for i in range(10):\n",
    "        h = fixed\n",
    "        l = [h]\n",
    "        for d in H.downwards:\n",
    "            l.append(hard_sample_binary_concrete(d(l[-1])))\n",
    "        l = torch.cat(l, dim=-1)\n",
    "        recovery = D(l).view(28,28).data.cpu().numpy()\n",
    "        blah[idx] = blah.get(idx, [])\n",
    "        blah[idx].append(recovery)\n",
    "plt.imshow(np.mean(np.array(blah[0]), 0))\n",
    "plt.show()\n",
    "plt.imshow(np.mean(np.array(blah[1]), 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    f, axes = plt.subplots(1, 10, sharey=True, figsize=(10,1))\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1.9, top=None,\n",
    "                    wspace=None, hspace=None)\n",
    "    fixed = hard_sample_binary_concrete(H.root_dist.unsqueeze(0))\n",
    "    print(fixed)\n",
    "    for i in range(10):\n",
    "        h = fixed\n",
    "        l = [h]\n",
    "        for d in H.downwards:\n",
    "            l.append(hard_sample_binary_concrete(d(l[-1])))\n",
    "        l = torch.cat(l, dim=-1)\n",
    "        recovery = D(l).view(28,28).data.cpu().numpy()\n",
    "        ax = axes[i]\n",
    "        ax.set_title(l.cpu().data.numpy())\n",
    "        ax.imshow(recovery)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.downwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    f, axes = plt.subplots(1, 10, sharey=True, figsize=(10,1))\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1.9, top=None,\n",
    "                    wspace=None, hspace=None)\n",
    "    a= [hard_sample_binary_concrete(H.root_dist.unsqueeze(0))]\n",
    "    for d in list(H.downwards)[:14]:\n",
    "        a.append(hard_sample_binary_concrete(d(a[-1])))\n",
    "    print(a)\n",
    "    for i in range(10):\n",
    "        l=a.copy()\n",
    "        for d in list(H.downwards)[14:]:\n",
    "            l.append(hard_sample_binary_concrete(d(l[-1])))\n",
    "        l = torch.cat(l, dim=-1)\n",
    "        recovery = D(l).view(28,28).data.cpu().numpy()\n",
    "        ax = axes[i]\n",
    "        ax.set_title(l.cpu().data.numpy())\n",
    "        ax.imshow(recovery)\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    f, axes = plt.subplots(1, 10, sharey=True, figsize=(10,1))\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1.9, top=None,\n",
    "                    wspace=None, hspace=None)\n",
    "    fixed = hard_sample_binary_concrete(H.root_dist.unsqueeze(0))\n",
    "    print(fixed)\n",
    "    for d in list(H.downwards)[:2]:\n",
    "        fixed = hard_sample_binary_concrete(d(fixed))\n",
    "    for i in range(10):\n",
    "        h = fixed\n",
    "        for d in list(H.downwards)[2:]:\n",
    "            h = hard_sample_binary_concrete(d(h))\n",
    "        recovery = D(h).view(28,28).data.cpu().numpy()\n",
    "        ax = axes[i]\n",
    "        ax.set_title(h.cpu().data.numpy())\n",
    "        ax.imshow(recovery)\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = torch.FloatTensor((0,0,0,0,0,0,0,0))\n",
    "for i in range(8):\n",
    "#     a = torch.FloatTensor((0,0,0,0,0,0,0,0))\n",
    "    a[i] = 1.\n",
    "    t = Variable(a).unsqueeze(0)\n",
    "    recovery = D(t).view(28,28).data.cpu().numpy()\n",
    "    plt.imshow(recovery)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "F.sigmoid(H.downwards[0](Variable(torch.Tensor([0.])).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.sigmoid(H.downwards[1](Variable(torch.Tensor([0., 0.]))).unsqueeze(0)))\n",
    "print(F.sigmoid(H.downwards[1](Variable(torch.Tensor([1., 0.]))).unsqueeze(0)))\n",
    "print(F.sigmoid(H.downwards[1](Variable(torch.Tensor([1., 1.]))).unsqueeze(0)))\n",
    "print(F.sigmoid(H.downwards[1](Variable(torch.Tensor([0., 1.]))).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
